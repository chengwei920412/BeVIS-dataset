
<head>
<meta http-equiv="Content-Language" content="zh-cn">
<meta http-equiv="Content-Type" content="text/html; charset=gb2312">
<title>BeVIS</title>

<style>
<!--
div.Section1
	{page:Section1;}
 table.MsoNormalTable
	{mso-style-parent:"";
	font-size:10.0pt;
	font-family:"Times New Roman","serif"}
table.TableGrid
	{border:1.0pt solid black;
	font-size:10.0pt;
	font-family:"Times New Roman";
	}
-->
</style>
<meta http-equiv="Content-Language" content="zh-cn">
<meta http-equiv="Content-Type" content="text/html; charset=gb2312">
<title>BeVIS</title>

<style>
<!--
div.Section1
	{page:Section1;}
 table.MsoNormalTable
	{mso-style-parent:"";
	font-size:10.0pt;
	font-family:"Times New Roman","serif"}
table.TableGrid
	{border:1.0pt solid black;
	font-size:10.0pt;
	font-family:"Times New Roman";
	}
-->
</style>
</head>

<html xmlns:v="urn:schemas-microsoft-com:vml" xmlns:o="urn:schemas-microsoft-com:office:office" xmlns="http://www.w3.org/TR/REC-html40">

<body>

<table class="MsoNormalTable" border="0" cellpadding="0" width="1217" id="table3" height="35">
	<tr>
	<td valign="top" style="width: 1211px; height: 31px; padding: .75pt" align="left">
		
		<p class="text"><span lang="en-us"><font face="Calibri" size="5" color="#0000FF">
		<b>SLAM for Indoor Parking: A Comprehensive Benchmark Dataset and a Tightly Coupled Semantic Framework</b></font></span>
		
		<p class="text"><span lang="en-us"><font face="Calibri" size="4" color="#0000FF">
			Xuan Shao<sup>1</sup>, Ying Shen<sup>1</sup>, Lin Zhang<sup>1</sup>, Shengjie Zhao<sup>1</sup>, Dandan Zhu<sup>2</sup> and Yicong Zhou<sup>3</sup></font></span>

		<p class="text"><font face="Calibri" size="4" color="#0000FF"><sup>1</sup><span lang="en-us">
		School of Software Engineering, Tongji University, Shanghai, China</span></font>
		<p class="text"><font face="Calibri" size="4" color="#0000FF"><sup>2</sup><span lang="en-us">
		Artificial Intelligence Institute, Shanghai Jiao Tong University, Shanghai, China</span></font>
		<p class="text"><font face="Calibri" size="4" color="#0000FF"><sup>3</sup><span lang="en-us">
		Department of Computer and Information Science, University of Macau, Macau, China</span></font>
	</td>
	</tr>
</table>

<hr>
<hr>
<p><span lang="en-us"><b><font face="Calibri" size="5">BeVIS Benchmark Dataset</font></b></span></p>
<p>
<span lang="en-us"><font face="Calibri" style="font-size: 13pt">1. 
<a href=https://pan.baidu.com/s/1GYCvroh8Bw5NHjxFQ_d0Wg>BeVIS Benchmark Dataset</a></font></span></p><p>(pw: 2bn0)</p>
	
<p>
<span lang="en-us"><font face="Calibri" style="font-size: 13pt">Currently in the BeVIS, there are totally 34,951 front-view images, 34,951 IMU motion data segments with each segment recording the vehicle motion between each two consecutive front-view images, and 12,032 surround-view images (synthesized from 48,128 fisheye images) collected in four indoor parking environments at Tongji University, covering a wide variety of real cases for autonomous indoor parking. One advantage of the BeVIS is the diversity of the conditions for data collection, ranging from static scenes with bright illumination to dynamic scenes with poor illumination. To exploit this advantage, we manually classify all the data in the BeVIS into three levels, “easy”, “medium” and “difficult”. In addition, another outstanding advantage of the BeVIS is the availability of the groundtruth trajectories for each sequence, ensuring objective evaluation of different SLAM systems for autonomous indoor parking.</font></span></p>
<p align="left"><img border="0" src="BeVIS.png" height="458"></p>

<p>
<span lang="en-us"><font face="Calibri" style="font-size: 13pt"> The BeVIS is only for acamedic use under the GNU General Public License Version 3 (GPLv3). For commercial purposes, please contact the authors for details.</font></span></p>

<hr>
<p><span lang="en-us"><b><font face="Calibri" size="5">VISSLAM-2</font></b></span></p>
<p>
<span lang="en-us"><font face="Calibri" style="font-size: 13pt">VISSLAM-2 is built on our previous work VISSLAM published in ACM MM 2020. Compared with VISSLAM that incorporates only adjacent parking-slots in the indoor parking environments, VISSLAM-2 provides a general form to model various semantic objects on the ground.</font></span></p>
<p align="left"><img border="0" src="VISSLAM-2.png" height="458"></p>
<hr>
<p align="justify"><font face="Calibri">Last update: <span lang="en-us">November 8, </span>2021</span></font></p>
</body>
</html>
